{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib3\n",
    "import time\n",
    "import numpy as np\n",
    "import json \n",
    "import csv\n",
    "import collections\n",
    "from IPython.display import display\n",
    "import math\n",
    "import re\n",
    "import spacy\n",
    "from scipy import sparse\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDRegressor, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/vacs_train_features.csv')\n",
    "df2 = pd.read_csv('data/vacs_test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df2])\n",
    "df2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.models.tokenizers.ru_tokenizer import RussianTokenizer\n",
    "tokenizer = RussianTokenizer(ngram_range=ngram_range=[1,2],lemmas=True,lowercase=True)\n",
    "def my_tokenize(txt):\n",
    "    ans = tokenizer([txt])\n",
    "    return ans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = ['Unnamed: 0',\n",
    " 'index',\n",
    " 'id',\n",
    " 'name',\n",
    " 'name.lemm',\n",
    " 'area.name',\n",
    " 'city',\n",
    " 'company',\n",
    " 'company_link',\n",
    " 'publication_date',\n",
    " 'salary_from',\n",
    " 'salary_currency',\n",
    " 'employment',\n",
    " 'employment.name',\n",
    " 'schedule',\n",
    " 'schedule.name',\n",
    " 'experience',\n",
    " 'experience.name',\n",
    " 'key_skills',\n",
    " 'specializations',\n",
    " 'specializations.names',\n",
    " 'description.lemm',\n",
    " 'type',\n",
    " 'log_salary_from',\n",
    " 'name0',\n",
    " 'log_salary_normalized',\n",
    " 'log_salary_normalized_year',\n",
    " 'median_salary_year',\n",
    " 'median_salary_year_month',\n",
    " 'salary_normalized',\n",
    " 'salary_normalized_year']\n",
    "\n",
    "y = df['log_salary_from']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=50000, shuffle=False)\n",
    "\n",
    "X_train['y'] = y_train\n",
    "X_train = X_train[(X_train['salary_from'] >= 20000) & (X_train['salary_from'] <= 100000) & (X_train['cyrillic_percentage'] >= 0.75)]\n",
    "y_train = X_train['y']\n",
    "\n",
    "X_train = X_train.drop(exclude_columns, axis=1).drop(['y','extracted_salary'], axis=1)\n",
    "extracted_salary = X_test['extracted_salary']\n",
    "X_test = X_test.drop(exclude_columns, axis=1).drop(['extracted_salary'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(tokenizer=my_tokenize, max_df=0.8, min_df=100, max_features=2000, use_idf=True, sublinear_tf=False)\n",
    "X_train_vec = vec.fit_transform(X_train['description'])\n",
    "X_test_vec = vec.transform(X_test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train.drop(['description'], inplace=True, axis=1)\n",
    "X_test.drop(['description'], inplace=True, axis=1)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([pd.DataFrame(X_train_scaled), pd.DataFrame(X_train_vec.todense())], axis=1)\n",
    "X_test = pd.concat([pd.DataFrame(X_test_scaled), pd.DataFrame(X_test_vec.todense())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = GradientBoostingRegressor(verbose=1, n_estimators=10, max_features='auto', max_depth=3)\n",
    "cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_train_pred = cls.predict(X_train)\n",
    "print('RMSE train', sqrt(mean_squared_error(y_train, sklearn_train_pred)))\n",
    "sklearn_test_pred = cls.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0\n",
    "dif = []\n",
    "for i,s in extracted_salary.iteritems():\n",
    "    if not math.isnan(s) and s > 0:\n",
    "        dif.append(abs(s - math.exp(sklearn_test_pred[l])))\n",
    "        sklearn_test_pred[l] = math.log(s)\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_pred = [round(math.exp(x)/1000)*1000 for x in sklearn_test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(salary_pred).to_csv('test_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
